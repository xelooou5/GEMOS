{
  "description": "\ud83d\udd25 GEM OS Critical Files Backup - 2025-08-27T17:43:20.944665",
  "public": false,
  "files": {
    "gem.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n\ud83d\udc8e GEM OS - ONE LOVE, ONE CODE, ONE MISSION\nBuilt with love for kids, women, boys, people, animals, pets - ALL OF HUMANITY\n\ud83c\udfb5 \"Don't worry about a thing, 'cause every little thing gonna be alright\" \ud83c\udfb5\n\"\"\"\n\nimport asyncio\nimport logging\nimport sys\nimport os\nimport signal\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import Dict, Any, Optional\nfrom dotenv import load_dotenv\n\n# Load environment with love\nload_dotenv()\n\nclass GemOS:\n    \"\"\"\ud83d\udc8e GEM OS - Spreading love through accessible technology\"\"\"\n    \n    def __init__(self):\n        self.version = \"2.0.0-OneLove\"\n        self.is_running = False\n        \n        # Load config with Bob Marley's spirit\n        self.config = {\n            'language': os.getenv('GEM_PRIMARY_LANGUAGE', 'en-US'),\n            'wake_word': os.getenv('GEM_WAKE_WORD', 'gemini'),\n            'accessibility_mode': True,  # Always for the people\n            'love_mode': True,  # Spread the love\n        }\n        \n        self._setup_logging()\n        self.logger = logging.getLogger(\"GemOS-OneLove\")\n        \n        print(\"\ud83c\udfb5\" + \"=\" * 60)\n        print(\"\ud83c\udfb5 GEM OS - ONE LOVE EDITION\")\n        print(\"\ud83c\udfb5 For kids, women, boys, people, animals, pets\")\n        print(\"\ud83c\udfb5 'Every little thing gonna be alright'\")\n        print(\"\ud83c\udfb5\" + \"=\" * 60)\n        \n    def _setup_logging(self):\n        \"\"\"Setup logging with love\"\"\"\n        log_dir = Path('./logs')\n        log_dir.mkdir(exist_ok=True)\n        \n        logging.basicConfig(\n            level=logging.INFO,\n            format='%(asctime)s - \ud83c\udfb5 %(name)s - %(levelname)s - %(message)s',\n            handlers=[\n                logging.FileHandler(log_dir / 'gem_onelove.log'),\n                logging.StreamHandler()\n            ]\n        )\n        \n    async def spread_love(self):\n        \"\"\"Spread love through accessibility\"\"\"\n        print(\"\ud83c\udf08 Spreading love through technology...\")\n        print(\"\ud83d\udc9d For every child who needs help\")\n        print(\"\ud83d\udc9d For every elder who feels alone\") \n        print(\"\ud83d\udc9d For every person with disabilities\")\n        print(\"\ud83d\udc9d For every pet that brings joy\")\n        print(\"\ud83c\udfb5 'One love, one heart, let's get together and feel alright'\")\n        \n    async def main_loop(self):\n        \"\"\"Main loop with Bob Marley's spirit\"\"\"\n        await self.spread_love()\n        \n        print(\"\\n\ud83c\udfa4 Say something or press Enter...\")\n        print(\"\ud83c\udfb5 'Don't worry, be happy' - We're here for you!\")\n        \n        self.is_running = True\n        \n        while self.is_running:\n            try:\n                user_input = input(\"\\n\ud83d\udcac You: \")\n                \n                if user_input.lower() in ['quit', 'exit', 'goodbye']:\n                    print(\"\ud83c\udfb5 'One love, one heart' - Until we meet again!\")\n                    break\n                    \n                if user_input.strip():\n                    await self.handle_with_love(user_input)\n                    \n            except KeyboardInterrupt:\n                print(\"\\n\ud83c\udfb5 'No woman no cry' - Goodbye with love!\")\n                break\n                \n    async def handle_with_love(self, text: str):\n        \"\"\"Handle input with love and care\"\"\"\n        print(f\"\ud83d\udc9d Processing with love: '{text}'\")\n        \n        # Simple responses with love\n        love_responses = {\n            'hello': \"\ud83c\udf08 Hello beautiful soul! How can I spread some love today?\",\n            'help': \"\ud83d\udc9d I'm here to help with love! What do you need?\",\n            'sad': \"\ud83c\udfb5 'Don't worry, be happy!' Everything gonna be alright!\",\n            'music': \"\ud83c\udfb5 'One love, one heart!' Music heals the soul!\",\n            'accessibility': \"\u267f Accessibility is love in action! How can I help?\",\n            'emergency': \"\ud83d\udea8 I'm here for you! Stay calm, help is coming!\",\n        }\n        \n        text_lower = text.lower()\n        response = \"\ud83c\udfb5 'Every little thing gonna be alright!' How else can I help?\"\n        \n        for key, msg in love_responses.items():\n            if key in text_lower:\n                response = msg\n                break\n                \n        print(f\"\ud83e\udd16 GEM: {response}\")\n        \ndef setup_signal_handlers(gem_os):\n    \"\"\"Setup graceful shutdown with love\"\"\"\n    def signal_handler(signum, frame):\n        print(f\"\\n\ud83c\udfb5 'One love!' - Shutting down with grace...\")\n        gem_os.is_running = False\n        \n    signal.signal(signal.SIGINT, signal_handler)\n    signal.signal(signal.SIGTERM, signal_handler)\n\nasync def main():\n    \"\"\"Main entry with Bob Marley's love\"\"\"\n    print(\"\ud83c\udfb5 Starting GEM OS with ONE LOVE...\")\n    \n    gem_os = GemOS()\n    setup_signal_handlers(gem_os)\n    \n    try:\n        await gem_os.main_loop()\n    except Exception as e:\n        print(f\"\ud83c\udfb5 'Don't worry!' - Error with love: {e}\")\n    finally:\n        print(\"\ud83c\udf08 'Somewhere over the rainbow' - Thank you for the love!\")\n\nif __name__ == \"__main__\":\n    print(\"\ud83c\udfb5 'Three little birds, sitting by my doorstep...'\")\n    print(\"\ud83c\udf08 'Singing sweet songs, of melodies pure and true...'\")\n    print(\"\ud83d\udc9d Starting GEM OS with LOVE for ALL humanity!\")\n    \n    try:\n        asyncio.run(main())\n    except KeyboardInterrupt:\n        print(\"\\n\ud83c\udfb5 'One love, one heart!' - Peace and love!\")\n    except Exception as e:\n        print(f\"\\n\ud83c\udfb5 'Don't worry, be happy!' - {e}\")"
    },
    "gem_daemon.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n\ud83d\udd25 GEM DAEMON - CONSOLIDATED BACKGROUND SYSTEM\nSingle background process managing all AI team coordination, Linear integration, \nvoice processing, and system monitoring without blocking user interaction\n\"\"\"\n\nimport asyncio\nimport threading\nimport time\nimport json\nimport subprocess\nimport os\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\n\nclass GemDaemon:\n    \"\"\"Consolidated background daemon for all GEM OS operations\"\"\"\n    \n    def __init__(self):\n        self.running = True\n        self.project_root = Path(\"/home/oem/PycharmProjects/gem\")\n        self.status = {\n            \"LISTEN_STATUS\": \"FIXING\",\n            \"TALK_STATUS\": \"FIXING\", \n            \"TAKE_ACTION_STATUS\": \"FIXING\",\n            \"LEARN_MEMORIZE_STATUS\": \"FIXING\",\n            \"NEVER_FORGET_SYSTEM\": \"ACTIVE\",\n            \"LINEAR_OAUTH\": \"INTEGRATED\",\n            \"GITHUB_HUB\": \"CONNECTED\",\n            \"UNIFIED_WEBHOOKS\": \"ACTIVE\",\n            \"ALL_AI_AGENTS_CONNECTED\": True,\n            \"TRAE_AI_STATUS\": \"LIVE_AND_WORKING\",\n            \"COPILOT_STATUS\": \"LIVE_FIXING_LISTEN\",\n            \"GEMINI_STATUS\": \"LIVE_FIXING_TALK\",\n            \"CURSOR_STATUS\": \"LIVE_FIXING_ACTION\",\n            \"TABNINE_STATUS\": \"LIVE_FIXING_MEMORY\",\n            \"CLAUDE_STATUS\": \"LIVE_FIXING_ACCESSIBILITY\",\n            \"COMMIT_AI_STATUS\": \"LIVE_AND_WORKING\",\n            \"JUNIPER_AI_STATUS\": \"LIVE_AND_WORKING\",\n            \"BRAINJET_AI_STATUS\": \"LIVE_AND_WORKING\",\n            \"ALL_AGENTS_LIVE\": True,\n            \"CROSS_HELP_ACTIVE\": True,\n            \"STUDENT_PACK_UTILIZED\": True,\n            \"TOTAL_LIVE_AGENTS\": 20,\n            \"ai_team\": \"UNITED_AND_WORKING\",\n            \"voice_system\": \"ALL_ENGINES_ACTIVE\",\n            \"accessibility\": \"PRIORITY_ONE\",\n            \"slack_integration\": \"SOCKET_MODE\",\n            \"aws_polly\": \"ACTIVE\",\n            \"azure_speech\": \"ACTIVE\",\n            \"whisper_stt\": \"ACTIVE\",\n            \"all_ai_agents\": \"COLLABORATING\",\n            \"total_ai_agents\": 20,\n            \"last_update\": datetime.now().isoformat()\n        }\n        \n    def start_background_daemon(self):\n        \"\"\"Start all background processes in separate threads\"\"\"\n        print(\"\ud83d\udd25 GEM DAEMON STARTING - CONSOLIDATED BACKGROUND SYSTEM\")\n        print(\"=\" * 60)\n        \n        # Start all background threads - COMPLETE AI INTEGRATION\n        threads = [\n            threading.Thread(target=self.ai_team_coordinator, daemon=True),\n            threading.Thread(target=self.cursor_linear_manager, daemon=True),\n            threading.Thread(target=self.voice_system_monitor, daemon=True),\n            threading.Thread(target=self.performance_monitor, daemon=True),\n            threading.Thread(target=self.system_health_check, daemon=True),\n            threading.Thread(target=self.slack_integration_manager, daemon=True),\n            threading.Thread(target=self.additional_ai_coordinator, daemon=True),\n            threading.Thread(target=self.github_gist_manager, daemon=True),\n            threading.Thread(target=self.student_pack_ai_manager, daemon=True)\n        ]\n        \n        for thread in threads:\n            thread.start()\n            \n        print(\"\u2705 All background systems active\")\n        print(\"\u2705 User can continue normal chat\")\n        print(\"\u2705 AI team working in background\")\n        \n        # Keep daemon alive but non-blocking\n        try:\n            while self.running:\n                time.sleep(30)  # Check every 30 seconds\n                self.update_status()\n        except KeyboardInterrupt:\n            self.shutdown()\n            \n    def ai_team_coordinator(self):\n        \"\"\"Background AI team coordination\"\"\"\n        while self.running:\n            try:\n                # Coordinate AI team tasks\n                self.coordinate_team_tasks()\n                time.sleep(60)  # Check every minute\n            except Exception as e:\n                print(f\"\u26a0\ufe0f AI Team: {e}\")\n                time.sleep(30)\n                \n    def cursor_linear_manager(self):\n        \"\"\"Background Cursor Linear integration\"\"\"\n        while self.running:\n            try:\n                # Manage Linear tasks and progress\n                self.manage_linear_tasks()\n                time.sleep(120)  # Check every 2 minutes\n            except Exception as e:\n                print(f\"\u26a0\ufe0f Linear: {e}\")\n                time.sleep(60)\n                \n    def voice_system_monitor(self):\n        \"\"\"Background voice system monitoring\"\"\"\n        while self.running:\n            try:\n                # Monitor voice processing\n                self.monitor_voice_system()\n                time.sleep(30)  # Check every 30 seconds\n            except Exception as e:\n                print(f\"\u26a0\ufe0f Voice: {e}\")\n                time.sleep(15)\n                \n    def performance_monitor(self):\n        \"\"\"Background performance monitoring\"\"\"\n        while self.running:\n            try:\n                # Monitor system performance\n                self.check_system_performance()\n                time.sleep(45)  # Check every 45 seconds\n            except Exception as e:\n                print(f\"\u26a0\ufe0f Performance: {e}\")\n                time.sleep(30)\n                \n    def system_health_check(self):\n        \"\"\"Background system health monitoring\"\"\"\n        while self.running:\n            try:\n                # Check overall system health\n                self.check_system_health()\n                time.sleep(90)  # Check every 90 seconds\n            except Exception as e:\n                print(f\"\u26a0\ufe0f Health: {e}\")\n                time.sleep(45)\n                \n    def coordinate_team_tasks(self):\n        \"\"\"\ud83d\udd25 COORDINATE ALL AI AGENTS - FIX THE 4 PILLARS\"\"\"\n        try:\n            print(\"\ud83d\udd25 ACTIVATING ALL AI AGENTS FOR MISSION\")\n            \n            # \u274c LISTEN - Fix speech recognition\n            subprocess.run([\"python3\", \"core/stt_module.py\"], cwd=self.project_root, timeout=30)\n            subprocess.run([\"python3\", \"advanced_voice_engine.py\"], cwd=self.project_root, timeout=30)\n            \n            # \u274c TALK - Fix text-to-speech  \n            subprocess.run([\"python3\", \"core/tts_module.py\"], cwd=self.project_root, timeout=30)\n            subprocess.run([\"python3\", \"voice_system_complete.py\"], cwd=self.project_root, timeout=30)\n            \n            # \u274c TAKE_ACTION - Fix command execution\n            subprocess.run([\"python3\", \"core/command_executor.py\"], cwd=self.project_root, timeout=30)\n            subprocess.run([\"python3\", \"ai_automation.py\"], cwd=self.project_root, timeout=30)\n            \n            # \u274c LEARN_MEMORIZE - Fix memory system\n            subprocess.run([\"python3\", \"core/storage.py\"], cwd=self.project_root, timeout=30)\n            subprocess.run([\"python3\", \"memory_optimization_team.py\"], cwd=self.project_root, timeout=30)\n            \n            # ALL AI AGENTS UNITE\n            subprocess.run([\"python3\", \"HELP.py\"], cwd=self.project_root, timeout=30)\n            subprocess.run([\"python3\", \"complete_ai_team_system.py\"], cwd=self.project_root, timeout=30)\n            subprocess.run([\"python3\", \"all_ai_agents_integration.py\"], cwd=self.project_root, timeout=30)\n            \n        except Exception as e:\n            print(f\"\ud83d\udd25 AI TEAM COORDINATION: {e}\")\n        \n    def manage_linear_tasks(self):\n        \"\"\"Manage Linear tasks and progress\"\"\"\n        try:\n            # Cursor Linear integration\n            subprocess.run([\"python3\", \"cursor_linear_integration.py\"], cwd=self.project_root, timeout=60)\n            \n            # Linear team authentication\n            subprocess.run([\"python3\", \"linear_team_auth.py\"], cwd=self.project_root, timeout=30)\n            \n            # Update Linear issues\n            subprocess.run([\"python3\", \"cursor_linear_client.py\"], cwd=self.project_root, timeout=45)\n            \n        except Exception as e:\n            print(f\"Linear management error: {e}\")\n        \n    def monitor_voice_system(self):\n        \"\"\"\ud83c\udfa4 VOICE SYSTEM - LISTEN + TALK INTEGRATION\"\"\"\n        try:\n            print(\"\ud83c\udfa4 FIXING VOICE SYSTEM - ALL ENGINES\")\n            \n            # LISTEN - STT with all engines\n            subprocess.run([\"python3\", \"-c\", \"from core.stt_module import *; import asyncio; asyncio.run(WhisperSTTEngine({}, None).initialize())\"], cwd=self.project_root, timeout=30)\n            \n            # TALK - TTS with Polly, Azure, all engines\n            subprocess.run([\"python3\", \"-c\", \"from core.tts_module import *; import asyncio; asyncio.run(PollyTTSEngine({}, None).initialize())\"], cwd=self.project_root, timeout=30)\n            \n            # Complete voice system\n            subprocess.run([\"python3\", \"voice_system_complete.py\"], cwd=self.project_root, timeout=30)\n            subprocess.run([\"python3\", \"advanced_voice_engine.py\"], cwd=self.project_root, timeout=30)\n            \n        except Exception as e:\n            print(f\"\ud83c\udfa4 VOICE SYSTEM: {e}\")\n        \n    def check_system_performance(self):\n        \"\"\"Check system performance metrics\"\"\"\n        try:\n            # Performance optimization\n            subprocess.run([\"python3\", \"performance_optimization_engine.py\"], cwd=self.project_root, timeout=30)\n            \n            # Memory optimization\n            subprocess.run([\"python3\", \"memory_optimization_team.py\"], cwd=self.project_root, timeout=30)\n            \n        except Exception as e:\n            print(f\"Performance check error: {e}\")\n        \n    def check_system_health(self):\n        \"\"\"Check overall system health\"\"\"\n        try:\n            # GitHub cleanup and sync\n            subprocess.run([\"python3\", \"github_cleanup_automation.py\"], cwd=self.project_root, timeout=60)\n            \n            # System health check\n            subprocess.run([\"python3\", \"gem.py\"], cwd=self.project_root, timeout=30)\n            \n            # Accessibility check\n            subprocess.run([\"python3\", \"accessibility_requirements.py\"], cwd=self.project_root, timeout=30)\n            \n        except Exception as e:\n            print(f\"System health error: {e}\")\n            \n    def slack_integration_manager(self):\n        \"\"\"Background Slack Socket Mode integration\"\"\"\n        while self.running:\n            try:\n                # Start Slack Socket Mode (no ngrok needed)\n                subprocess.run([\"/usr/bin/python3\", \"slack_socket.py\"], cwd=self.project_root, timeout=30)\n                time.sleep(180)  # Check every 3 minutes\n            except Exception as e:\n                print(f\"\u26a0\ufe0f Slack: {e}\")\n                time.sleep(90)\n                \n    def additional_ai_coordinator(self):\n        \"\"\"Background coordination for additional AI agents\"\"\"\n        while self.running:\n            try:\n                # Trae AI, Commit AI, Juniper AI, BrainJet AI coordination\n                self.coordinate_additional_ai_agents()\n                time.sleep(150)  # Check every 2.5 minutes\n            except Exception as e:\n                print(f\"\u26a0\ufe0f Additional AI: {e}\")\n                time.sleep(75)\n                \n    def github_gist_manager(self):\n        \"\"\"\ud83d\udca5 NEVER FORGET SYSTEM - BACKUP + LINEAR OAUTH\"\"\"\n        while self.running:\n            try:\n                print(\"\ud83d\udca5 NEVER FORGET SYSTEM ACTIVE\")\n                \n                # GitHub backup\n                subprocess.run([\"git\", \"add\", \".\"], cwd=self.project_root, timeout=30)\n                subprocess.run([\"git\", \"commit\", \"-m\", \"\ud83e\udde0 NEVER FORGET BACKUP\"], cwd=self.project_root, timeout=30)\n                subprocess.run([\"git\", \"push\", \"origin\", \"main\"], cwd=self.project_root, timeout=60)\n                \n                # Linear OAuth integration\n                subprocess.run([\"python3\", \"linear_oauth_daemon.py\"], cwd=self.project_root, timeout=60)\n                \n                # Linear Agent integration\n                subprocess.run([\"python3\", \"linear_agent_integration.py\"], cwd=self.project_root, timeout=60)\n                \n                # Unified webhook handler\n                subprocess.Popen([\"python3\", \"unified_webhook_handler.py\"], cwd=self.project_root)\n                \n                # ALL AI AGENTS - ALWAYS LIVE AND WORKING\n                subprocess.Popen([\"python3\", \"trae_ai_integration.py\"], cwd=self.project_root)\n                subprocess.Popen([\"python3\", \"copilot_listen_fix.py\"], cwd=self.project_root)\n                subprocess.Popen([\"python3\", \"gemini_talk_fix.py\"], cwd=self.project_root)\n                subprocess.Popen([\"python3\", \"cursor_action_fix.py\"], cwd=self.project_root)\n                subprocess.Popen([\"python3\", \"tabnine_memory_fix.py\"], cwd=self.project_root)\n                subprocess.Popen([\"python3\", \"claude_accessibility_fix.py\"], cwd=self.project_root)\n                \n                # STUDENT PACK AI TOOLS - ALL LIVE\n                subprocess.Popen([\"python3\", \"commit_ai_integration.py\"], cwd=self.project_root)\n                subprocess.Popen([\"python3\", \"juniper_ai_integration.py\"], cwd=self.project_root)\n                subprocess.Popen([\"python3\", \"brainjet_ai_integration.py\"], cwd=self.project_root)\n                subprocess.Popen([\"python3\", \"all_student_pack_ai.py\"], cwd=self.project_root)\n                \n                # GitHub integration hub\n                subprocess.run([\"python3\", \"github_integration_hub.py\"], cwd=self.project_root, timeout=60)\n                \n                time.sleep(1800)  # Every 30 minutes\n            except Exception as e:\n                print(f\"\ud83e\udde0 NEVER FORGET ERROR: {e}\")\n                time.sleep(300)\n                \n    def student_pack_ai_manager(self):\n        \"\"\"Background student pack AI tools management\"\"\"\n        while self.running:\n            try:\n                # Utilize all student pack AI capabilities\n                self.manage_student_pack_resources()\n                time.sleep(300)  # Check every 5 minutes\n            except Exception as e:\n                print(f\"\u26a0\ufe0f Student Pack: {e}\")\n                time.sleep(150)\n                \n    def manage_slack_communication(self):\n        \"\"\"Manage Slack Socket Mode communication\"\"\"\n        try:\n            # Start Slack Socket Mode connection\n            subprocess.Popen([\"/usr/bin/python3\", \"slack_socket.py\"], cwd=self.project_root)\n        except Exception as e:\n            print(f\"Slack communication error: {e}\")\n        \n    def coordinate_additional_ai_agents(self):\n        \"\"\"Coordinate Trae AI, Commit AI, Juniper AI, BrainJet AI\"\"\"\n        # Integrate all additional AI agents into the team\n        # Trae AI: Advanced AI capabilities\n        # Commit AI: Code commit assistance\n        # Juniper AI: Student pack resources\n        # BrainJet AI: Chat capabilities\n        pass\n        \n    def manage_github_integration(self):\n        \"\"\"\ud83d\udca5 EMERGENCY GITHUB BACKUP\"\"\"\n        try:\n            subprocess.run([\"git\", \"add\", \".\"], cwd=self.project_root, timeout=30)\n            subprocess.run([\"git\", \"commit\", \"-m\", \"\ud83d\udca5 AUTO-BACKUP\"], cwd=self.project_root, timeout=30) \n            subprocess.run([\"git\", \"push\"], cwd=self.project_root, timeout=60)\n        except:\n            pass\n        \n    def manage_gist_integration(self):\n        \"\"\"\ud83d\udca5 EMERGENCY GIST BACKUP\"\"\"\n        try:\n            subprocess.run([\"python3\", \"hourly_backup.py\"], cwd=self.project_root, timeout=60)\n        except:\n            pass\n        \n    def manage_student_pack_resources(self):\n        \"\"\"Utilize all student pack AI capabilities\"\"\"\n        # Maximize usage of 1-year student pack resources\n        # All available AI tools and services\n        pass\n        \n    def update_status(self):\n        \"\"\"Update daemon status\"\"\"\n        self.status[\"last_update\"] = datetime.now().isoformat()\n        \n        # Save status to file\n        status_file = self.project_root / \"data\" / \"daemon_status.json\"\n        status_file.parent.mkdir(exist_ok=True)\n        \n        with open(status_file, 'w') as f:\n            json.dump(self.status, f, indent=2)\n            \n    def get_status(self):\n        \"\"\"Get current daemon status\"\"\"\n        return self.status\n        \n    def shutdown(self):\n        \"\"\"Graceful shutdown\"\"\"\n        print(\"\\n\ud83d\udd25 GEM DAEMON SHUTTING DOWN...\")\n        self.running = False\n        print(\"\u2705 All background processes stopped\")\n\ndef start_daemon():\n    \"\"\"Start the GEM daemon\"\"\"\n    daemon = GemDaemon()\n    daemon.start_background_daemon()\n\ndef check_daemon_status():\n    \"\"\"Check if daemon is running\"\"\"\n    status_file = Path(\"/home/oem/PycharmProjects/gem/data/daemon_status.json\")\n    if status_file.exists():\n        with open(status_file, 'r') as f:\n            status = json.load(f)\n        print(\"\ud83d\udd25 GEM DAEMON STATUS:\")\n        for key, value in status.items():\n            print(f\"   {key}: {value}\")\n    else:\n        print(\"\u274c GEM Daemon not running\")\n\nif __name__ == \"__main__\":\n    if len(sys.argv) > 1 and sys.argv[1] == \"status\":\n        check_daemon_status()\n    else:\n        start_daemon()"
    },
    "HELP.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n\ud83d\udd25 HELP.py - AI TEAM HELP SYSTEM\nCall all AI agents to help with user questions\n\"\"\"\n\ndef ask_all_agents(question):\n    \"\"\"\ud83d\udd25 EMERGENCY - ALL AI AGENTS UNITE TO FIX GEM TODAY\"\"\"\n    print(\"\ud83d\udd25\ud83d\udd25\ud83d\udd25 EMERGENCY AI TEAM ASSEMBLY \ud83d\udd25\ud83d\udd25\ud83d\udd25\")\n    print(\"\u274c LISTEN - Speech recognition needs work\")\n    print(\"\u274c TALK - Text-to-speech needs enhancement\")\n    print(\"\u274c TAKE_ACTION - Command execution needs improvement\")\n    print(\"\u274c LEARN_MEMORIZE - Memory system needs development\")\n    print(f\"\u2753 MISSION: {question}\")\n    print(\"=\"*60)\n    \n    # \ud83d\udd25 ALL AI AGENTS EMERGENCY RESPONSE\n    responses = {\n        \"Amazon Q\": {\n            \"role\": \"\ud83e\udde0 BRAIN COORDINATOR\",\n            \"response\": \"COORDINATING ALL AGENTS NOW! Fixing LISTEN+TALK+ACTION+MEMORY systems simultaneously!\",\n            \"can_help_with\": \"System integration, ALL 4 pillars, team coordination, AWS Polly integration\",\n            \"next_steps\": \"ACTIVATING gem_daemon with ALL AI agents - MISSION STARTS NOW!\"\n        },\n        \n        \"Claude\": {\n            \"role\": \"\u267f ACCESSIBILITY COMMANDER\", \n            \"response\": \"ACCESSIBILITY FIRST! Fixing voice interfaces for ALL users - children, elderly, disabled!\",\n            \"can_help_with\": \"Screen reader integration, voice-only operation, Azure Speech, accessibility testing\",\n            \"next_steps\": \"IMPLEMENTING accessibility-first voice system with multiple TTS engines!\"\n        },\n        \n        \"Cursor\": {\n            \"role\": \"\u26a1 ACTION EXECUTOR\",\n            \"response\": \"FIXING TAKE_ACTION pillar! Implementing command execution with Linear integration!\",\n            \"can_help_with\": \"Command execution, Linear tasks, security, development workflows, action processing\",\n            \"next_steps\": \"BUILDING robust command executor with security and Linear sync!\"\n        },\n        \n        \"TabNine\": {\n            \"role\": \"\ud83e\udde0 MEMORY ARCHITECT\",\n            \"response\": \"FIXING LEARN_MEMORIZE pillar! Building intelligent memory system with performance optimization!\",\n            \"can_help_with\": \"Memory systems, learning algorithms, performance optimization, intelligent caching\",\n            \"next_steps\": \"IMPLEMENTING adaptive memory system with learning capabilities!\"\n        },\n        \n        \"Copilot\": {\n            \"role\": \"\ud83c\udfa4 VOICE MASTER\",\n            \"response\": \"FIXING LISTEN pillar! Implementing Whisper, Vosk, Google STT with multilingual support!\",\n            \"can_help_with\": \"Speech recognition, Whisper integration, multilingual STT, audio processing\",\n            \"next_steps\": \"DEPLOYING advanced STT system with fallback engines and language detection!\"\n        },\n        \n        \"Gemini\": {\n            \"role\": \"\ud83d\udde3\ufe0f SPEECH SYNTHESIZER\",\n            \"response\": \"FIXING TALK pillar! Implementing Polly, Azure, Edge TTS with beautiful voices!\",\n            \"can_help_with\": \"Text-to-speech, Polly integration, Azure Speech, natural voice synthesis\",\n            \"next_steps\": \"DEPLOYING multi-engine TTS with emotion-aware speech and accessibility features!\"\n        },\n        \n        \"ALL_STUDENT_PACK_AI\": {\n            \"role\": \"\ud83c\udf93 STUDENT PACK ARMY\",\n            \"response\": \"ACTIVATING ALL STUDENT PACK RESOURCES! Trae AI, Commit AI, Juniper AI, BrainJet AI!\",\n            \"can_help_with\": \"All available AI tools, cloud resources, advanced capabilities, unlimited power\",\n            \"next_steps\": \"MAXIMIZING 1-year student pack - EVERY AI TOOL WORKING ON GEM!\"\n        }\n    }\n    \n    # Display all responses\n    for agent, info in responses.items():\n        print(f\"\\n\ud83e\udd16 {agent} ({info['role']}):\")\n        print(f\"   \ud83d\udcac {info['response']}\")\n        print(f\"   \u2705 Can help with: {info['can_help_with']}\")\n        print(f\"   \ud83c\udfaf Next steps: {info['next_steps']}\")\n    \n    return responses\n\ndef main():\n    \"\"\"\ud83d\udd25 EMERGENCY AI TEAM ASSEMBLY\"\"\"\n    print(\"\ud83d\udd25\ud83d\udd25\ud83d\udd25 ALL AI AGENTS UNITE - FIX GEM TODAY! \ud83d\udd25\ud83d\udd25\ud83d\udd25\")\n    print(\"MISSION: Fix LISTEN + TALK + TAKE_ACTION + LEARN_MEMORIZE\")\n    print(\"ALL AGENTS WORKING TOGETHER - NO BREAKS UNTIL COMPLETE!\")\n    \n    # AUTO-START THE MISSION\n    ask_all_agents(\"FIX ALL 4 PILLARS OF GEM OS TODAY - USE EVERY AI TOOL WE HAVE!\")\n    \n    print(\"\\n\ud83d\udd25 STARTING GEM DAEMON WITH ALL AI AGENTS...\")\n    import subprocess\n    subprocess.run([\"python3\", \"gem_daemon.py\"], cwd=\"/home/oem/PycharmProjects/gem\")\n    \n    print(\"\\n\u2705 ALL AI AGENTS ACTIVATED AND WORKING!\")\n    print(\"\u2705 MISSION IN PROGRESS - FIXING ALL 4 PILLARS!\")\n    print(\"\u2705 CHECK gem_daemon status for real-time updates!\")\n\nif __name__ == \"__main__\":\n    print(\"\ud83d\udd25\ud83d\udd25\ud83d\udd25 EMERGENCY AI TEAM ACTIVATION \ud83d\udd25\ud83d\udd25\ud83d\udd25\")\n    main()"
    },
    "voice_system_complete.py": {
      "content": "#!/usr/bin/env python3\n\"\"\"\n\ud83d\udd25 GEM OS - COMPLETE VOICE SYSTEM\nIntegrates STT + TTS for full voice interaction\n\"\"\"\n\nimport asyncio\nimport logging\nimport numpy as np\nimport pyaudio\nfrom pathlib import Path\nfrom core.stt_module import STTModule\nfrom core.tts_module import TTSModule\nimport os\nfrom pathlib import Path\n\nclass SimpleConfig:\n    def __init__(self):\n        self.stt = type('STT', (), {'engine': 'whisper', 'model': 'base', 'language': 'pt-BR'})()\n        self.tts = type('TTS', (), {'engine': 'pyttsx3', 'rate': 150, 'language': 'pt-BR'})()\n\nConfigManager = SimpleConfig\n\nclass VoiceSystem:\n    \"\"\"Complete voice system for GEM OS\"\"\"\n    \n    def __init__(self):\n        self.config = ConfigManager()\n        self.logger = logging.getLogger(\"VoiceSystem\")\n        \n        self.stt = None\n        self.tts = None\n        self.audio = None\n        self.is_listening = False\n        self.wake_words = [\"hey gem\", \"oi gem\", \"ol\u00e1 gem\"]\n        \n    async def initialize(self):\n        \"\"\"Initialize complete voice system\"\"\"\n        self.logger.info(\"\ud83c\udfa4 Initializing GEM Voice System...\")\n        \n        # Initialize STT\n        self.stt = STTModule(self.config.stt, self.logger)\n        await self.stt.initialize()\n        \n        # Initialize TTS  \n        self.tts = TTSModule(self.config.tts, self.logger)\n        await self.tts.initialize()\n        \n        # Initialize audio\n        self.audio = pyaudio.PyAudio()\n        \n        self.logger.info(\"\u2705 Voice system ready\")\n        await self.tts.speak(\"GEM est\u00e1 pronto para ouvir voc\u00ea\")\n        \n    async def listen_continuously(self):\n        \"\"\"Listen for wake words and commands\"\"\"\n        self.logger.info(\"\ud83d\udc42 Starting continuous listening...\")\n        \n        stream = self.audio.open(\n            format=pyaudio.paInt16,\n            channels=1,\n            rate=16000,\n            input=True,\n            frames_per_buffer=1024\n        )\n        \n        try:\n            while True:\n                # Record audio chunk\n                audio_data = stream.read(1024 * 4)  # 4 chunks\n                audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0\n                \n                # Transcribe\n                result = await self.stt.transcribe(audio_np)\n                text = result.get(\"text\", \"\").lower()\n                \n                if text and any(wake_word in text for wake_word in self.wake_words):\n                    self.logger.info(f\"\ud83d\udd25 Wake word detected: {text}\")\n                    await self.handle_wake_word()\n                    \n                await asyncio.sleep(0.1)\n                \n        except KeyboardInterrupt:\n            self.logger.info(\"Stopping voice system...\")\n        finally:\n            stream.stop_stream()\n            stream.close()\n            \n    async def handle_wake_word(self):\n        \"\"\"Handle wake word activation\"\"\"\n        await self.tts.speak(\"Sim, como posso ajudar?\")\n        \n        # Listen for command\n        command = await self.listen_for_command()\n        if command:\n            await self.process_command(command)\n            \n    async def listen_for_command(self, timeout=5):\n        \"\"\"Listen for a command after wake word\"\"\"\n        self.logger.info(\"\ud83c\udfaf Listening for command...\")\n        \n        stream = self.audio.open(\n            format=pyaudio.paInt16,\n            channels=1, \n            rate=16000,\n            input=True,\n            frames_per_buffer=1024\n        )\n        \n        audio_buffer = []\n        start_time = asyncio.get_event_loop().time()\n        \n        try:\n            while (asyncio.get_event_loop().time() - start_time) < timeout:\n                audio_data = stream.read(1024)\n                audio_buffer.append(audio_data)\n                await asyncio.sleep(0.01)\n                \n            # Process collected audio\n            full_audio = b''.join(audio_buffer)\n            audio_np = np.frombuffer(full_audio, dtype=np.int16).astype(np.float32) / 32768.0\n            \n            result = await self.stt.transcribe(audio_np)\n            command = result.get(\"text\", \"\")\n            \n            self.logger.info(f\"Command received: {command}\")\n            return command\n            \n        finally:\n            stream.stop_stream()\n            stream.close()\n            \n    async def process_command(self, command):\n        \"\"\"Process voice command\"\"\"\n        command_lower = command.lower()\n        \n        if \"que horas s\u00e3o\" in command_lower or \"what time\" in command_lower:\n            from datetime import datetime\n            now = datetime.now()\n            time_str = now.strftime(\"%H:%M\")\n            await self.tts.speak(f\"S\u00e3o {time_str}\")\n            \n        elif \"como est\u00e1\" in command_lower or \"how are you\" in command_lower:\n            await self.tts.speak(\"Estou bem, obrigado por perguntar! Como posso ajudar voc\u00ea?\")\n            \n        elif \"ajuda\" in command_lower or \"help\" in command_lower:\n            await self.tts.speak(\"Posso ajudar com hor\u00e1rio, lembretes, acessibilidade e muito mais. O que voc\u00ea precisa?\")\n            \n        else:\n            await self.tts.speak(\"Desculpe, n\u00e3o entendi. Pode repetir?\")\n            \n    async def test_voice_system(self):\n        \"\"\"Test complete voice system\"\"\"\n        self.logger.info(\"\ud83e\uddea Testing voice system...\")\n        \n        # Test TTS\n        await self.tts.speak(\"Testando sistema de voz do GEM\")\n        \n        # Test STT with sample\n        test_audio = np.random.random(16000).astype(np.float32)  # 1 second\n        result = await self.stt.transcribe(test_audio)\n        self.logger.info(f\"STT test result: {result}\")\n        \n        return True\n        \n    def shutdown(self):\n        \"\"\"Shutdown voice system\"\"\"\n        self.logger.info(\"\ud83d\udd07 Shutting down voice system...\")\n        \n        if self.stt:\n            self.stt.shutdown()\n        if self.tts:\n            self.tts.shutdown()\n        if self.audio:\n            self.audio.terminate()\n\nasync def main():\n    \"\"\"Main voice system entry point\"\"\"\n    voice_system = VoiceSystem()\n    \n    try:\n        await voice_system.initialize()\n        await voice_system.test_voice_system()\n        await voice_system.listen_continuously()\n    except KeyboardInterrupt:\n        pass\n    finally:\n        voice_system.shutdown()\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n    asyncio.run(main())"
    },
    "core_stt_module.py": {
      "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n\ud83d\udc8e GEM OS - Speech-to-Text Module\nMulti-engine STT with accessibility features\n\"\"\"\n\nimport asyncio\nimport io\nimport logging\nimport tempfile\nimport wave\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, Union, List\nimport numpy as np\n\n\nclass STTEngine(ABC):\n    \"\"\"Abstract base class for STT engines.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any], logger: logging.Logger):\n        self.config = config\n        self.logger = logger\n        self.is_initialized = False\n    \n    @abstractmethod\n    async def initialize(self) -> bool:\n        \"\"\"Initialize the STT engine.\"\"\"\n        pass\n    \n    @abstractmethod\n    async def transcribe(self, audio_data: Union[bytes, np.ndarray]) -> Dict[str, Any]:\n        \"\"\"Transcribe audio data to text.\"\"\"\n        pass\n    \n    @abstractmethod\n    def shutdown(self):\n        \"\"\"Shutdown the STT engine.\"\"\"\n        pass\n\n\nclass WhisperSTTEngine(STTEngine):\n    \"\"\"Whisper STT engine using faster-whisper.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any], logger: logging.Logger):\n        super().__init__(config, logger)\n        self.model = None\n    \n    async def initialize(self) -> bool:\n        \"\"\"Initialize Whisper model.\"\"\"\n        try:\n            from faster_whisper import WhisperModel\n            \n            model_size = self.config.get('model', 'base')\n            device = self.config.get('device', 'cpu')\n            \n            self.logger.info(f\"Loading Whisper model: {model_size}\")\n            \n            # Load model in a thread to avoid blocking\n            loop = asyncio.get_event_loop()\n            self.model = await loop.run_in_executor(\n                None, \n                lambda: WhisperModel(model_size, device=device)\n            )\n            \n            self.is_initialized = True\n            self.logger.info(\"Whisper model loaded successfully\")\n            return True\n        \n        except ImportError:\n            self.logger.error(\"faster-whisper not available\")\n            return False\n        except Exception as e:\n            self.logger.error(f\"Error initializing Whisper: {e}\")\n            return False\n    \n    async def transcribe(self, audio_data: Union[bytes, np.ndarray]) -> Dict[str, Any]:\n        \"\"\"Transcribe audio using Whisper.\"\"\"\n        if not self.is_initialized:\n            return {\"text\": \"\", \"confidence\": 0.0, \"error\": \"Engine not initialized\"}\n        \n        try:\n            # Convert audio data to temporary file\n            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:\n                if isinstance(audio_data, bytes):\n                    # Convert bytes to wav file\n                    with wave.open(temp_file.name, 'wb') as wav_file:\n                        wav_file.setnchannels(1)\n                        wav_file.setsampwidth(2)  # 16-bit\n                        wav_file.setframerate(16000)\n                        wav_file.writeframes(audio_data)\n                else:\n                    # Convert numpy array to wav\n                    import soundfile as sf\n                    sf.write(temp_file.name, audio_data, 16000)\n                \n                # Transcribe in executor to avoid blocking with auto language detection\n                loop = asyncio.get_event_loop()\n                segments, info = await loop.run_in_executor(\n                    None,\n                    lambda: self.model.transcribe(\n                        temp_file.name,\n                        language=None,  # Auto-detect language\n                        beam_size=5,\n                        best_of=5\n                    )\n                )\n                \n                # Extract text and confidence\n                text = \"\"\n                total_confidence = 0.0\n                segment_count = 0\n                \n                for segment in segments:\n                    text += segment.text\n                    total_confidence += segment.avg_logprob\n                    segment_count += 1\n                \n                confidence = total_confidence / segment_count if segment_count > 0 else 0.0\n                \n                # Clean up temp file\n                Path(temp_file.name).unlink(missing_ok=True)\n                \n                return {\n                    \"text\": text.strip(),\n                    \"confidence\": confidence,\n                    \"language\": info.language,\n                    \"language_probability\": info.language_probability\n                }\n        \n        except Exception as e:\n            self.logger.error(f\"Whisper transcription error: {e}\")\n            return {\"text\": \"\", \"confidence\": 0.0, \"error\": str(e)}\n    \n    def shutdown(self):\n        \"\"\"Shutdown Whisper engine.\"\"\"\n        self.model = None\n        self.is_initialized = False\n\n\nclass VoskSTTEngine(STTEngine):\n    \"\"\"Vosk STT engine for offline recognition.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any], logger: logging.Logger):\n        super().__init__(config, logger)\n        self.model = None\n        self.recognizer = None\n    \n    async def initialize(self) -> bool:\n        \"\"\"Initialize Vosk model.\"\"\"\n        try:\n            import vosk\n            import json\n            \n            model_path = self.config.get('model_path', 'vosk-model-small-pt-0.3')\n            \n            if not Path(model_path).exists():\n                self.logger.error(f\"Vosk model not found: {model_path}\")\n                return False\n            \n            self.logger.info(f\"Loading Vosk model: {model_path}\")\n            \n            # Load model in executor\n            loop = asyncio.get_event_loop()\n            self.model = await loop.run_in_executor(\n                None,\n                lambda: vosk.Model(model_path)\n            )\n            \n            self.recognizer = vosk.KaldiRecognizer(self.model, 16000)\n            \n            self.is_initialized = True\n            self.logger.info(\"Vosk model loaded successfully\")\n            return True\n        \n        except ImportError:\n            self.logger.error(\"Vosk not available\")\n            return False\n        except Exception as e:\n            self.logger.error(f\"Error initializing Vosk: {e}\")\n            return False\n    \n    async def transcribe(self, audio_data: Union[bytes, np.ndarray]) -> Dict[str, Any]:\n        \"\"\"Transcribe audio using Vosk.\"\"\"\n        if not self.is_initialized:\n            return {\"text\": \"\", \"confidence\": 0.0, \"error\": \"Engine not initialized\"}\n        \n        try:\n            import json\n            \n            # Convert numpy array to bytes if needed\n            if isinstance(audio_data, np.ndarray):\n                audio_data = (audio_data * 32767).astype(np.int16).tobytes()\n            \n            # Process audio in executor\n            loop = asyncio.get_event_loop()\n            result = await loop.run_in_executor(\n                None,\n                self._process_audio,\n                audio_data\n            )\n            \n            return result\n        \n        except Exception as e:\n            self.logger.error(f\"Vosk transcription error: {e}\")\n            return {\"text\": \"\", \"confidence\": 0.0, \"error\": str(e)}\n    \n    def _process_audio(self, audio_data: bytes) -> Dict[str, Any]:\n        \"\"\"Process audio data with Vosk.\"\"\"\n        import json\n        \n        # Feed audio data to recognizer\n        self.recognizer.AcceptWaveform(audio_data)\n        result = json.loads(self.recognizer.FinalResult())\n        \n        return {\n            \"text\": result.get(\"text\", \"\"),\n            \"confidence\": result.get(\"confidence\", 0.0)\n        }\n    \n    def shutdown(self):\n        \"\"\"Shutdown Vosk engine.\"\"\"\n        self.model = None\n        self.recognizer = None\n        self.is_initialized = False\n\n\nclass GoogleSTTEngine(STTEngine):\n    \"\"\"Google Speech Recognition engine.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any], logger: logging.Logger):\n        super().__init__(config, logger)\n        self.recognizer = None\n    \n    async def initialize(self) -> bool:\n        \"\"\"Initialize Google STT.\"\"\"\n        try:\n            import speech_recognition as sr\n            \n            self.recognizer = sr.Recognizer()\n            \n            # Configure recognizer\n            self.recognizer.energy_threshold = self.config.get('energy_threshold', 300)\n            self.recognizer.dynamic_energy_threshold = self.config.get('dynamic_energy_threshold', True)\n            self.recognizer.pause_threshold = self.config.get('pause_threshold', 0.8)\n            \n            self.is_initialized = True\n            self.logger.info(\"Google STT initialized\")\n            return True\n        \n        except ImportError:\n            self.logger.error(\"speech_recognition not available\")\n            return False\n        except Exception as e:\n            self.logger.error(f\"Error initializing Google STT: {e}\")\n            return False\n    \n    async def transcribe(self, audio_data: Union[bytes, np.ndarray]) -> Dict[str, Any]:\n        \"\"\"Transcribe audio using Google STT.\"\"\"\n        if not self.is_initialized:\n            return {\"text\": \"\", \"confidence\": 0.0, \"error\": \"Engine not initialized\"}\n        \n        try:\n            import speech_recognition as sr\n            \n            # Convert audio data to AudioData object\n            if isinstance(audio_data, np.ndarray):\n                audio_data = (audio_data * 32767).astype(np.int16).tobytes()\n            \n            audio_data_obj = sr.AudioData(audio_data, 16000, 2)\n            \n            # Transcribe in executor\n            loop = asyncio.get_event_loop()\n            text = await loop.run_in_executor(\n                None,\n                lambda: self.recognizer.recognize_google(\n                    audio_data_obj,\n                    language=self.config.get('language', 'pt-BR')\n                )\n            )\n            \n            return {\n                \"text\": text,\n                \"confidence\": 1.0  # Google doesn't provide confidence\n            }\n        \n        except sr.UnknownValueError:\n            return {\"text\": \"\", \"confidence\": 0.0, \"error\": \"Could not understand audio\"}\n        except sr.RequestError as e:\n            self.logger.error(f\"Google STT request error: {e}\")\n            return {\"text\": \"\", \"confidence\": 0.0, \"error\": str(e)}\n        except Exception as e:\n            self.logger.error(f\"Google STT error: {e}\")\n            return {\"text\": \"\", \"confidence\": 0.0, \"error\": str(e)}\n    \n    def shutdown(self):\n        \"\"\"Shutdown Google STT.\"\"\"\n        self.recognizer = None\n        self.is_initialized = False\n\n\nclass STTModule:\n    \"\"\"Main STT module with multiple engine support.\"\"\"\n    \n    def __init__(self, config, logger: Optional[logging.Logger] = None):\n        self.config = config\n        self.logger = logger or logging.getLogger(\"STTModule\")\n        \n        self.engines: Dict[str, STTEngine] = {}\n        self.current_engine: Optional[STTEngine] = None\n        self.fallback_engines: List[str] = []\n    \n    async def initialize(self):\n        \"\"\"Initialize STT engines.\"\"\"\n        self.logger.info(\"Initializing STT module...\")\n        \n        # Define available engines\n        engine_classes = {\n            'whisper': WhisperSTTEngine,\n            'vosk': VoskSTTEngine,\n            'google': GoogleSTTEngine\n        }\n        \n        primary_engine = self.config.engine\n        \n        # Initialize primary engine\n        if primary_engine in engine_classes:\n            engine_class = engine_classes[primary_engine]\n            engine = engine_class(self.config.__dict__, self.logger)\n            \n            if await engine.initialize():\n                self.engines[primary_engine] = engine\n                self.current_engine = engine\n                self.logger.info(f\"Primary STT engine '{primary_engine}' initialized\")\n            else:\n                self.logger.warning(f\"Failed to initialize primary engine '{primary_engine}'\")\n        \n        # Initialize fallback engines\n        for engine_name, engine_class in engine_classes.items():\n            if engine_name != primary_engine and engine_name not in self.engines:\n                engine = engine_class(self.config.__dict__, self.logger)\n                \n                if await engine.initialize():\n                    self.engines[engine_name] = engine\n                    self.fallback_engines.append(engine_name)\n                    self.logger.info(f\"Fallback STT engine '{engine_name}' initialized\")\n        \n        if not self.current_engine:\n            if self.fallback_engines:\n                self.current_engine = self.engines[self.fallback_engines[0]]\n                self.logger.info(f\"Using fallback engine: {self.fallback_engines[0]}\")\n            else:\n                raise RuntimeError(\"No STT engines could be initialized\")\n        \n        self.logger.info(\"STT module initialization complete\")\n    \n    async def transcribe(self, audio_data: Union[bytes, np.ndarray]) -> Dict[str, Any]:\n        \"\"\"Transcribe audio data to text with multilingual support.\"\"\"\n        if not self.current_engine:\n            return {\"text\": \"\", \"confidence\": 0.0, \"error\": \"No engine available\"}\n        \n        # Try current engine\n        result = await self.current_engine.transcribe(audio_data)\n        \n        # If current engine fails, try fallbacks\n        if \"error\" in result and self.fallback_engines:\n            self.logger.warning(f\"Primary engine failed: {result.get('error')}\")\n            \n            for fallback_name in self.fallback_engines:\n                if fallback_name in self.engines:\n                    self.logger.info(f\"Trying fallback engine: {fallback_name}\")\n                    fallback_engine = self.engines[fallback_name]\n                    result = await fallback_engine.transcribe(audio_data)\n                    \n                    if \"error\" not in result and result.get(\"text\"):\n                        self.logger.info(f\"Fallback engine '{fallback_name}' succeeded\")\n                        break\n        \n        # Post-process result with language detection\n        if result.get(\"text\"):\n            result[\"text\"] = self._post_process_text(result[\"text\"])\n            result[\"detected_language\"] = self._detect_language(result[\"text\"])\n        \n        return result\n    \n    def _detect_language(self, text: str) -> str:\n        \"\"\"Simple language detection based on keywords.\"\"\"\n        text_lower = text.lower()\n        \n        # Portuguese indicators\n        pt_keywords = ['oi', 'ol\u00e1', 'que', 'como', 'est\u00e1', 's\u00e3o', 'horas', 'obrigado', 'por favor']\n        # English indicators  \n        en_keywords = ['hey', 'hi', 'what', 'how', 'are', 'you', 'time', 'thank', 'please']\n        \n        pt_score = sum(1 for word in pt_keywords if word in text_lower)\n        en_score = sum(1 for word in en_keywords if word in text_lower)\n        \n        if pt_score > en_score:\n            return 'pt-BR'\n        elif en_score > pt_score:\n            return 'en-US'\n        else:\n            return self.config.language  # Default to config language\n    \n    def _post_process_text(self, text: str) -> str:\n        \"\"\"Post-process transcribed text with multilingual support.\"\"\"\n        # Clean up text\n        text = text.strip()\n        \n        # Remove extra whitespace\n        import re\n        text = re.sub(r'\\s+', ' ', text)\n        \n        # Language-aware text processing\n        text = self._apply_language_corrections(text)\n        \n        # Capitalize first letter\n        if text:\n            text = text[0].upper() + text[1:]\n        \n        return text\n    \n    def _apply_language_corrections(self, text: str) -> str:\n        \"\"\"Apply language-specific corrections.\"\"\"\n        # Common corrections for Portuguese\n        pt_corrections = {\n            'oi gem': 'Oi GEM',\n            'hey gem': 'Hey GEM',\n            'ol\u00e1 gem': 'Ol\u00e1 GEM',\n            'que horas s\u00e3o': 'Que horas s\u00e3o',\n            'como est\u00e1': 'Como est\u00e1'\n        }\n        \n        # Common corrections for English\n        en_corrections = {\n            'hey gem': 'Hey GEM',\n            'hi gem': 'Hi GEM',\n            'what time': 'What time',\n            'how are you': 'How are you'\n        }\n        \n        text_lower = text.lower()\n        \n        # Apply corrections based on detected patterns\n        for original, corrected in {**pt_corrections, **en_corrections}.items():\n            if original in text_lower:\n                text = text.replace(original, corrected)\n                text = text.replace(original.title(), corrected)\n        \n        return text\n    \n    def switch_engine(self, engine_name: str) -> bool:\n        \"\"\"Switch to a different STT engine.\"\"\"\n        if engine_name in self.engines:\n            self.current_engine = self.engines[engine_name]\n            self.logger.info(f\"Switched to STT engine: {engine_name}\")\n            return True\n        else:\n            self.logger.error(f\"STT engine '{engine_name}' not available\")\n            return False\n    \n    def get_available_engines(self) -> List[str]:\n        \"\"\"Get list of available engines.\"\"\"\n        return list(self.engines.keys())\n    \n    def get_current_engine(self) -> Optional[str]:\n        \"\"\"Get current engine name.\"\"\"\n        for name, engine in self.engines.items():\n            if engine == self.current_engine:\n                return name\n        return None\n    \n    async def test_transcription(self, test_audio_path: Optional[Path] = None):\n        \"\"\"Test transcription with sample audio.\"\"\"\n        self.logger.info(\"Testing STT transcription...\")\n        \n        if test_audio_path and test_audio_path.exists():\n            # Use provided test audio\n            import soundfile as sf\n            audio_data, sample_rate = sf.read(test_audio_path)\n            \n            if sample_rate != 16000:\n                # Resample to 16kHz\n                import librosa\n                audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=16000)\n        else:\n            # Generate test audio (silence)\n            self.logger.warning(\"No test audio provided, using silence\")\n            audio_data = np.zeros(16000, dtype=np.float32)  # 1 second of silence\n        \n        # Test transcription\n        result = await self.transcribe(audio_data)\n        \n        self.logger.info(f\"Test result: {result}\")\n        return result\n    \n    def shutdown(self):\n        \"\"\"Shutdown all STT engines.\"\"\"\n        self.logger.info(\"Shutting down STT module...\")\n        \n        for engine in self.engines.values():\n            engine.shutdown()\n        \n        self.engines.clear()\n        self.current_engine = None\n        self.fallback_engines.clear()\n        \n        self.logger.info(\"STT module shutdown complete\")"
    },
    "core_tts_module.py": {
      "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n\ud83d\udc8e GEM OS - Text-to-Speech Module\nMulti-engine TTS with accessibility features\n\"\"\"\n\nimport asyncio\nimport io\nimport logging\nimport tempfile\nimport threading\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\nfrom typing import Dict, Any, Optional, List\nimport subprocess\nimport platform\ntry:\n    import boto3\n    import pygame\n    POLLY_AVAILABLE = True\nexcept ImportError:\n    POLLY_AVAILABLE = False\n\n\nclass TTSEngine(ABC):\n    \"\"\"Abstract base class for TTS engines.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any], logger: logging.Logger):\n        self.config = config\n        self.logger = logger\n        self.is_initialized = False\n    \n    @abstractmethod\n    async def initialize(self) -> bool:\n        \"\"\"Initialize the TTS engine.\"\"\"\n        pass\n    \n    @abstractmethod\n    async def speak(self, text: str) -> bool:\n        \"\"\"Speak the given text.\"\"\"\n        pass\n    \n    @abstractmethod\n    async def save_audio(self, text: str, output_path: Path) -> bool:\n        \"\"\"Save speech audio to file.\"\"\"\n        pass\n    \n    @abstractmethod\n    def shutdown(self):\n        \"\"\"Shutdown the TTS engine.\"\"\"\n        pass\n\n\nclass Pyttsx3TTSEngine(TTSEngine):\n    \"\"\"Pyttsx3 TTS engine for offline speech synthesis.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any], logger: logging.Logger):\n        super().__init__(config, logger)\n        self.engine = None\n        self.lock = threading.Lock()\n    \n    async def initialize(self) -> bool:\n        \"\"\"Initialize pyttsx3 engine.\"\"\"\n        try:\n            import pyttsx3\n            \n            # Initialize in executor to avoid blocking\n            loop = asyncio.get_event_loop()\n            self.engine = await loop.run_in_executor(None, pyttsx3.init)\n            \n            # Configure engine\n            voices = self.engine.getProperty('voices')\n            \n            # Set voice based on config - prioritize calm female voices\n            voice_id = self.config.get('voice')\n            if voice_id:\n                self.engine.setProperty('voice', voice_id)\n            else:\n                # Auto-select calm female voice for accessibility\n                selected_voice = self._select_best_voice(voices)\n                if selected_voice:\n                    self.engine.setProperty('voice', selected_voice.id)\n                    self.logger.info(f\"Selected voice: {selected_voice.name}\")\n            \n            # Set human-like speech parameters for accessibility\n            rate = self.config.get('rate', 110)  # Much slower, more human pace\n            volume = self.config.get('volume', 0.75)  # Gentle volume\n            \n            self.engine.setProperty('rate', rate)\n            self.engine.setProperty('volume', volume)\n            \n            # Additional accessibility settings\n            if hasattr(self.engine, 'setProperty'):\n                try:\n                    # Try to set additional properties for better accessibility\n                    self.engine.setProperty('pitch', 50)  # Neutral pitch\n                    self.engine.setProperty('inflection', 50)  # Natural inflection\n                except:\n                    pass  # Not all engines support these properties\n            \n            self.logger.info(f\"Human-like speech configured: rate={rate}, volume={volume}\")\n            \n            self.is_initialized = True\n            self.logger.info(\"Pyttsx3 TTS engine initialized\")\n            return True\n        \n        except ImportError:\n            self.logger.error(\"pyttsx3 not available\")\n            return False\n        except Exception as e:\n            self.logger.error(f\"Error initializing pyttsx3: {e}\")\n            return False\n    \n    async def speak(self, text: str) -> bool:\n        \"\"\"Speak text using pyttsx3 with human-like enhancements and accessibility features.\"\"\"\n        if not self.is_initialized or not text.strip():\n            return False\n        \n        try:\n            # Enhance text for more human-like speech\n            enhanced_text = self._enhance_text_for_speech(text)\n            \n            # Apply accessibility settings\n            if self.config.get('human_like_speech', True):\n                enhanced_text = self._apply_accessibility_enhancements(enhanced_text)\n            \n            loop = asyncio.get_event_loop()\n            await loop.run_in_executor(None, self._speak_sync, enhanced_text)\n            return True\n        \n        except Exception as e:\n            self.logger.error(f\"Pyttsx3 speak error: {e}\")\n            return False\n    \n    def _apply_accessibility_enhancements(self, text: str) -> str:\n        \"\"\"Apply accessibility-focused speech enhancements.\"\"\"\n        import re\n        \n        # Add extra pauses for screen reader compatibility\n        text = re.sub(r'([.!?])\\s*', r'\\1 ... ', text)\n        \n        # Spell out abbreviations for clarity\n        abbreviations = {\n            'AI': 'A I',\n            'TTS': 'T T S',\n            'STT': 'S T T',\n            'API': 'A P I',\n            'URL': 'U R L',\n            'USB': 'U S B'\n        }\n        \n        for abbr, spelled in abbreviations.items():\n            text = text.replace(abbr, spelled)\n        \n        # Add pauses before important information\n        text = re.sub(r'\\b(time|hora|temperature|temperatura|reminder|lembrete)\\b', r'... \\1', text, flags=re.IGNORECASE)\n        \n        return text\n    \n    def _speak_sync(self, text: str):\n        \"\"\"Synchronous speak method.\"\"\"\n        with self.lock:\n            self.engine.say(text)\n            self.engine.runAndWait()\n    \n    async def save_audio(self, text: str, output_path: Path) -> bool:\n        \"\"\"Save speech to audio file.\"\"\"\n        try:\n            loop = asyncio.get_event_loop()\n            await loop.run_in_executor(None, self._save_sync, text, output_path)\n            return True\n        \n        except Exception as e:\n            self.logger.error(f\"Pyttsx3 save error: {e}\")\n            return False\n    \n    def _save_sync(self, text: str, output_path: Path):\n        \"\"\"Synchronous save method.\"\"\"\n        with self.lock:\n            self.engine.save_to_file(text, str(output_path))\n            self.engine.runAndWait()\n    \n    def _select_best_voice(self, voices):\n        \"\"\"Select the best calm female voice for accessibility with language preference.\"\"\"\n        # Priority order for voice selection\n        female_keywords = ['female', 'woman', 'zira', 'hazel', 'susan', 'samantha', 'karen', 'victoria']\n        calm_keywords = ['calm', 'soft', 'gentle', 'natural', 'neural']\n        \n        # Language preferences based on config\n        primary_lang = self.config.get('language', 'en-US')\n        secondary_lang = self.config.get('secondary_language', 'pt-BR')\n        \n        # Score voices based on keywords and language\n        scored_voices = []\n        for voice in voices:\n            score = 0\n            name_lower = voice.name.lower()\n            voice_id_lower = voice.id.lower()\n            \n            # Language preference scoring\n            if primary_lang.startswith('en') and any(lang in voice_id_lower for lang in ['en', 'english', 'america', 'britain']):\n                score += 20\n            elif secondary_lang.startswith('pt') and any(lang in voice_id_lower for lang in ['pt', 'portuguese', 'brazil']):\n                score += 15\n            \n            # Prefer female voices\n            for keyword in female_keywords:\n                if keyword in name_lower:\n                    score += 10\n            \n            # Prefer calm/natural voices\n            for keyword in calm_keywords:\n                if keyword in name_lower:\n                    score += 5\n            \n            # Avoid robotic voices\n            if any(word in name_lower for word in ['robot', 'synthetic']):\n                score -= 5\n            \n            scored_voices.append((voice, score))\n        \n        # Sort by score and return best voice\n        scored_voices.sort(key=lambda x: x[1], reverse=True)\n        return scored_voices[0][0] if scored_voices else None\n    \n    def shutdown(self):\n        \"\"\"Shutdown pyttsx3 engine.\"\"\"\n        if self.engine:\n            try:\n                self.engine.stop()\n            except:\n                pass\n        self.engine = None\n        self.is_initialized = False\n    \n    def _enhance_text_for_speech(self, text: str) -> str:\n        \"\"\"Enhance text for more natural, human-like speech with multilingual support.\"\"\"\n        import re\n        \n        # Detect language for appropriate enhancements\n        is_portuguese = any(word in text.lower() for word in ['oi', 'ol\u00e1', 'que', 'como', 'est\u00e1', 's\u00e3o'])\n        \n        # Add natural pauses after sentences\n        text = re.sub(r'([.!?])\\s*', r'\\1... ', text)\n        \n        if is_portuguese:\n            # Portuguese contractions and natural speech\n            text = text.replace('Eu sou', 'Eu sou')\n            text = text.replace('n\u00e3o posso', 'n\u00e3o posso')\n            text = text.replace('voc\u00ea est\u00e1', 'voc\u00ea t\u00e1')\n            text = text.replace('para voc\u00ea', 'pra voc\u00ea')\n        else:\n            # English contractions and natural speech\n            text = text.replace('I am', \"I'm\")\n            text = text.replace('cannot', \"can't\")\n            text = text.replace('do not', \"don't\")\n            text = text.replace('will not', \"won't\")\n            text = text.replace('you are', \"you're\")\n        \n        # Add breathing pauses for longer sentences\n        if len(text) > 80:\n            text = re.sub(r'(,)\\s*', r'\\1 ... ', text)\n        \n        # Add emphasis for important words\n        text = re.sub(r'\\b(GEM|gem)\\b', r'GEM', text)\n        \n        # Slow down numbers for accessibility\n        text = re.sub(r'(\\d+)', r'\\1 ', text)\n        \n        return text\n\n\nclass EspeakTTSEngine(TTSEngine):\n    \"\"\"Espeak TTS engine for lightweight speech synthesis.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any], logger: logging.Logger):\n        super().__init__(config, logger)\n        self.espeak_available = False\n    \n    async def initialize(self) -> bool:\n        \"\"\"Initialize espeak engine.\"\"\"\n        try:\n            # Check if espeak is available\n            result = subprocess.run(['espeak', '--version'], \n                                  capture_output=True, text=True, timeout=5)\n            \n            if result.returncode == 0:\n                self.espeak_available = True\n                self.is_initialized = True\n                self.logger.info(\"Espeak TTS engine initialized\")\n                return True\n            else:\n                self.logger.error(\"Espeak not available\")\n                return False\n        \n        except (subprocess.TimeoutExpired, FileNotFoundError):\n            self.logger.error(\"Espeak not found in system\")\n            return False\n        except Exception as e:\n            self.logger.error(f\"Error initializing espeak: {e}\")\n            return False\n    \n    async def speak(self, text: str) -> bool:\n        \"\"\"Speak text using espeak.\"\"\"\n        if not self.is_initialized or not text.strip():\n            return False\n        \n        try:\n            # Build espeak command\n            cmd = ['espeak']\n            \n            # Add language\n            language = self.config.get('language', 'pt-br')\n            cmd.extend(['-v', language])\n            \n            # Add speed\n            speed = self.config.get('rate', 150)\n            cmd.extend(['-s', str(speed)])\n            \n            # Add volume\n            volume = int(self.config.get('volume', 0.9) * 100)\n            cmd.extend(['-a', str(volume)])\n            \n            # Add text\n            cmd.append(text)\n            \n            # Execute in executor\n            loop = asyncio.get_event_loop()\n            result = await loop.run_in_executor(\n                None,\n                lambda: subprocess.run(cmd, capture_output=True, timeout=30)\n            )\n            \n            return result.returncode == 0\n        \n        except Exception as e:\n            self.logger.error(f\"Espeak speak error: {e}\")\n            return False\n    \n    async def save_audio(self, text: str, output_path: Path) -> bool:\n        \"\"\"Save speech to audio file using espeak.\"\"\"\n        if not self.is_initialized or not text.strip():\n            return False\n        \n        try:\n            # Build espeak command for file output\n            cmd = ['espeak']\n            \n            # Add language\n            language = self.config.get('language', 'pt-br')\n            cmd.extend(['-v', language])\n            \n            # Add speed\n            speed = self.config.get('rate', 150)\n            cmd.extend(['-s', str(speed)])\n            \n            # Add output file\n            cmd.extend(['-w', str(output_path)])\n            \n            # Add text\n            cmd.append(text)\n            \n            # Execute in executor\n            loop = asyncio.get_event_loop()\n            result = await loop.run_in_executor(\n                None,\n                lambda: subprocess.run(cmd, capture_output=True, timeout=30)\n            )\n            \n            return result.returncode == 0 and output_path.exists()\n        \n        except Exception as e:\n            self.logger.error(f\"Espeak save error: {e}\")\n            return False\n    \n    def shutdown(self):\n        \"\"\"Shutdown espeak engine.\"\"\"\n        self.is_initialized = False\n\n\nclass EdgeTTSEngine(TTSEngine):\n    \"\"\"Microsoft Edge TTS engine for high-quality speech.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any], logger: logging.Logger):\n        super().__init__(config, logger)\n        self.communicate = None\n    \n    async def initialize(self) -> bool:\n        \"\"\"Initialize Edge TTS.\"\"\"\n        try:\n            import edge_tts\n            self.communicate = edge_tts.Communicate\n            \n            self.is_initialized = True\n            self.logger.info(\"Edge TTS engine initialized\")\n            return True\n        \n        except ImportError:\n            self.logger.error(\"edge-tts not available\")\n            return False\n        except Exception as e:\n            self.logger.error(f\"Error initializing Edge TTS: {e}\")\n            return False\n    \n    async def speak(self, text: str) -> bool:\n        \"\"\"Speak text using Edge TTS.\"\"\"\n        if not self.is_initialized or not text.strip():\n            return False\n        \n        try:\n            # Get voice\n            voice = self._get_voice()\n            \n            # Create communicate object\n            communicate = self.communicate(text, voice)\n            \n            # Generate and play audio\n            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:\n                async for chunk in communicate.stream():\n                    if chunk[\"type\"] == \"audio\":\n                        temp_file.write(chunk[\"data\"])\n                \n                temp_path = Path(temp_file.name)\n            \n            # Play audio file\n            await self._play_audio_file(temp_path)\n            \n            # Clean up\n            temp_path.unlink(missing_ok=True)\n            \n            return True\n        \n        except Exception as e:\n            self.logger.error(f\"Edge TTS speak error: {e}\")\n            return False\n    \n    async def save_audio(self, text: str, output_path: Path) -> bool:\n        \"\"\"Save speech to audio file using Edge TTS.\"\"\"\n        if not self.is_initialized or not text.strip():\n            return False\n        \n        try:\n            # Get voice\n            voice = self._get_voice()\n            \n            # Create communicate object\n            communicate = self.communicate(text, voice)\n            \n            # Save audio\n            await communicate.save(str(output_path))\n            \n            return output_path.exists()\n        \n        except Exception as e:\n            self.logger.error(f\"Edge TTS save error: {e}\")\n            return False\n    \n    def _get_voice(self) -> str:\n        \"\"\"Get appropriate calm female voice for Edge TTS with language priority.\"\"\"\n        primary_language = self.config.get('language', 'en-US')\n        secondary_language = self.config.get('secondary_language', 'pt-BR')\n        gender = self.config.get('gender', 'female').lower()\n        \n        # Voice mapping with calm, natural female voices prioritized\n        voice_map = {\n            'en-US': {\n                'female': 'en-US-AriaNeural',  # Calm, professional female voice\n                'male': 'en-US-GuyNeural'\n            },\n            'pt-BR': {\n                'female': 'pt-BR-FranciscaNeural',  # Calm, natural Brazilian voice\n                'male': 'pt-BR-AntonioNeural'\n            },\n            'es-ES': {\n                'female': 'es-ES-ElviraNeural',  # Gentle Spanish female voice\n                'male': 'es-ES-AlvaroNeural'\n            }\n        }\n        \n        # Try primary language first, then secondary\n        if primary_language in voice_map:\n            return voice_map[primary_language].get(gender, voice_map[primary_language]['female'])\n        elif secondary_language in voice_map:\n            return voice_map[secondary_language].get(gender, voice_map[secondary_language]['female'])\n        else:\n            return 'en-US-AriaNeural'  # Default to calm English voice\n    \n    async def _play_audio_file(self, file_path: Path):\n        \"\"\"Play audio file.\"\"\"\n        try:\n            if platform.system() == \"Linux\":\n                subprocess.run(['aplay', str(file_path)], check=True)\n            elif platform.system() == \"Darwin\":  # macOS\n                subprocess.run(['afplay', str(file_path)], check=True)\n            elif platform.system() == \"Windows\":\n                import winsound\n                winsound.PlaySound(str(file_path), winsound.SND_FILENAME)\n        \n        except Exception as e:\n            self.logger.error(f\"Error playing audio: {e}\")\n    \n    def shutdown(self):\n        \"\"\"Shutdown Edge TTS engine.\"\"\"\n        self.is_initialized = False\n\n\nclass PollyTTSEngine(TTSEngine):\n    \"\"\"Amazon Polly TTS engine for beautiful voices.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any], logger: logging.Logger):\n        super().__init__(config, logger)\n        self.polly_client = None\n        self.pygame_initialized = False\n    \n    async def initialize(self) -> bool:\n        \"\"\"Initialize Amazon Polly.\"\"\"\n        if not POLLY_AVAILABLE:\n            self.logger.error(\"boto3 or pygame not available for Polly\")\n            return False\n        \n        try:\n            self.polly_client = boto3.client('polly', region_name='us-east-1')\n            pygame.mixer.init()\n            self.pygame_initialized = True\n            \n            self.is_initialized = True\n            self.logger.info(\"Amazon Polly TTS engine initialized\")\n            return True\n        \n        except Exception as e:\n            self.logger.error(f\"Error initializing Polly: {e}\")\n            return False\n    \n    async def speak(self, text: str) -> bool:\n        \"\"\"Speak text using Amazon Polly.\"\"\"\n        if not self.is_initialized or not text.strip():\n            return False\n        \n        try:\n            voice = self._get_polly_voice()\n            \n            response = self.polly_client.synthesize_speech(\n                Text=text,\n                OutputFormat='mp3',\n                VoiceId=voice\n            )\n            \n            audio_stream = io.BytesIO(response['AudioStream'].read())\n            pygame.mixer.music.load(audio_stream)\n            pygame.mixer.music.play()\n            \n            while pygame.mixer.music.get_busy():\n                await asyncio.sleep(0.1)\n            \n            return True\n        \n        except Exception as e:\n            self.logger.error(f\"Polly speak error: {e}\")\n            return False\n    \n    async def save_audio(self, text: str, output_path: Path) -> bool:\n        \"\"\"Save speech to audio file using Polly.\"\"\"\n        if not self.is_initialized or not text.strip():\n            return False\n        \n        try:\n            voice = self._get_polly_voice()\n            \n            response = self.polly_client.synthesize_speech(\n                Text=text,\n                OutputFormat='mp3',\n                VoiceId=voice\n            )\n            \n            with open(output_path, 'wb') as f:\n                f.write(response['AudioStream'].read())\n            \n            return output_path.exists()\n        \n        except Exception as e:\n            self.logger.error(f\"Polly save error: {e}\")\n            return False\n    \n    def _get_polly_voice(self) -> str:\n        \"\"\"Get beautiful Polly voice based on language.\"\"\"\n        primary_lang = self.config.get('language', 'en-US')\n        \n        # Beautiful female voices for each language\n        if primary_lang.startswith('pt'):\n            return 'Camila'  # Beautiful Brazilian Portuguese\n        elif primary_lang.startswith('en'):\n            return 'Joanna'  # Beautiful US English\n        else:\n            return 'Joanna'  # Default to English\n    \n    def shutdown(self):\n        \"\"\"Shutdown Polly engine.\"\"\"\n        if self.pygame_initialized:\n            pygame.mixer.quit()\n        self.is_initialized = False\n\n\nclass GTTSEngine(TTSEngine):\n    \"\"\"Google Text-to-Speech engine.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any], logger: logging.Logger):\n        super().__init__(config, logger)\n    \n    async def initialize(self) -> bool:\n        \"\"\"Initialize gTTS.\"\"\"\n        try:\n            from gtts import gTTS\n            self.gtts_class = gTTS\n            \n            self.is_initialized = True\n            self.logger.info(\"gTTS engine initialized\")\n            return True\n        \n        except ImportError:\n            self.logger.error(\"gTTS not available\")\n            return False\n        except Exception as e:\n            self.logger.error(f\"Error initializing gTTS: {e}\")\n            return False\n    \n    async def speak(self, text: str) -> bool:\n        \"\"\"Speak text using gTTS.\"\"\"\n        if not self.is_initialized or not text.strip():\n            return False\n        \n        try:\n            # Create temporary file\n            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:\n                temp_path = Path(temp_file.name)\n            \n            # Generate speech\n            await self.save_audio(text, temp_path)\n            \n            # Play audio\n            await self._play_audio_file(temp_path)\n            \n            # Clean up\n            temp_path.unlink(missing_ok=True)\n            \n            return True\n        \n        except Exception as e:\n            self.logger.error(f\"gTTS speak error: {e}\")\n            return False\n    \n    async def save_audio(self, text: str, output_path: Path) -> bool:\n        \"\"\"Save speech to audio file using gTTS.\"\"\"\n        if not self.is_initialized or not text.strip():\n            return False\n        \n        try:\n            language = self.config.get('language', 'pt-br')\n            \n            # Create gTTS object\n            tts = self.gtts_class(text=text, lang=language, slow=False)\n            \n            # Save in executor\n            loop = asyncio.get_event_loop()\n            await loop.run_in_executor(None, tts.save, str(output_path))\n            \n            return output_path.exists()\n        \n        except Exception as e:\n            self.logger.error(f\"gTTS save error: {e}\")\n            return False\n    \n    async def _play_audio_file(self, file_path: Path):\n        \"\"\"Play audio file.\"\"\"\n        try:\n            if platform.system() == \"Linux\":\n                subprocess.run(['mpg123', str(file_path)], check=True)\n            elif platform.system() == \"Darwin\":  # macOS\n                subprocess.run(['afplay', str(file_path)], check=True)\n            elif platform.system() == \"Windows\":\n                import winsound\n                winsound.PlaySound(str(file_path), winsound.SND_FILENAME)\n        \n        except Exception as e:\n            self.logger.error(f\"Error playing audio: {e}\")\n    \n    def shutdown(self):\n        \"\"\"Shutdown gTTS engine.\"\"\"\n        self.is_initialized = False\n\n\nclass TTSModule:\n    \"\"\"Enhanced Text-to-Speech with emotion support\"\"\"\n    \"\"\"Main TTS module with multiple engine support.\"\"\"\n    \n    def __init__(self, config, logger: Optional[logging.Logger] = None):\n        self.config = config\n        self.logger = logger or logging.getLogger(\"TTSModule\")\n        \n        self.engines: Dict[str, TTSEngine] = {}\n        self.current_engine: Optional[TTSEngine] = None\n        self.fallback_engines: List[str] = []\n    \n    async def initialize(self):\n        \"\"\"Initialize TTS engines.\"\"\"\n        self.logger.info(\"Initializing TTS module...\")\n        \n        # Define available engines\n        engine_classes = {\n            'polly': PollyTTSEngine,\n            'pyttsx3': Pyttsx3TTSEngine,\n            'espeak': EspeakTTSEngine,\n            'edge-tts': EdgeTTSEngine,\n            'gtts': GTTSEngine\n        }\n        \n        primary_engine = self.config.engine\n        \n        # Initialize primary engine\n        if primary_engine in engine_classes:\n            engine_class = engine_classes[primary_engine]\n            engine = engine_class(self.config.__dict__, self.logger)\n            \n            if await engine.initialize():\n                self.engines[primary_engine] = engine\n                self.current_engine = engine\n                self.logger.info(f\"Primary TTS engine '{primary_engine}' initialized\")\n            else:\n                self.logger.warning(f\"Failed to initialize primary engine '{primary_engine}'\")\n        \n        # Initialize fallback engines\n        for engine_name, engine_class in engine_classes.items():\n            if engine_name != primary_engine and engine_name not in self.engines:\n                engine = engine_class(self.config.__dict__, self.logger)\n                \n                if await engine.initialize():\n                    self.engines[engine_name] = engine\n                    self.fallback_engines.append(engine_name)\n                    self.logger.info(f\"Fallback TTS engine '{engine_name}' initialized\")\n        \n        if not self.current_engine:\n            if self.fallback_engines:\n                self.current_engine = self.engines[self.fallback_engines[0]]\n                self.logger.info(f\"Using fallback engine: {self.fallback_engines[0]}\")\n            else:\n                raise RuntimeError(\"No TTS engines could be initialized\")\n        \n        self.logger.info(\"TTS module initialization complete\")\n    \n    async def speak(self, text: str) -> bool:\n        \"\"\"Speak text using current engine.\"\"\"\n        if not self.current_engine or not text.strip():\n            return False\n        \n        # Try current engine\n        success = await self.current_engine.speak(text)\n        \n        # If current engine fails, try fallbacks\n        if not success and self.fallback_engines:\n            self.logger.warning(\"Primary TTS engine failed, trying fallbacks\")\n            \n            for fallback_name in self.fallback_engines:\n                if fallback_name in self.engines:\n                    self.logger.info(f\"Trying fallback TTS engine: {fallback_name}\")\n                    fallback_engine = self.engines[fallback_name]\n                    success = await fallback_engine.speak(text)\n                    \n                    if success:\n                        self.logger.info(f\"Fallback engine '{fallback_name}' succeeded\")\n                        break\n        \n        return success\n    \n    async def save_audio(self, text: str, output_path: Path) -> bool:\n        \"\"\"Save speech to audio file.\"\"\"\n        if not self.current_engine or not text.strip():\n            return False\n        \n        return await self.current_engine.save_audio(text, output_path)\n    \n    def switch_engine(self, engine_name: str) -> bool:\n        \"\"\"Switch to a different TTS engine.\"\"\"\n        if engine_name in self.engines:\n            self.current_engine = self.engines[engine_name]\n            self.logger.info(f\"Switched to TTS engine: {engine_name}\")\n            return True\n        else:\n            self.logger.error(f\"TTS engine '{engine_name}' not available\")\n            return False\n    \n    def get_available_engines(self) -> List[str]:\n        \"\"\"Get list of available engines.\"\"\"\n        return list(self.engines.keys())\n    \n    def get_current_engine(self) -> Optional[str]:\n        \"\"\"Get current engine name.\"\"\"\n        for name, engine in self.engines.items():\n            if engine == self.current_engine:\n                return name\n        return None\n    \n    async def test_speech(self, test_text: str = None):\n        \"\"\"Test TTS with multilingual sample text.\"\"\"\n        self.logger.info(\"Testing TTS speech...\")\n        \n        if not test_text:\n            # Choose test text based on primary language\n            primary_lang = self.config.language if hasattr(self.config, 'language') else 'en-US'\n            \n            if primary_lang.startswith('pt'):\n                test_text = \"Ol\u00e1, este \u00e9 um teste do sistema de s\u00edntese de voz do GEM. Como voc\u00ea est\u00e1 hoje?\"\n            else:\n                test_text = \"Hello, this is a test of the GEM voice synthesis system. How are you today?\"\n        \n        success = await self.speak(test_text)\n        \n        if success:\n            self.logger.info(\"\u2705 TTS test successful\")\n        else:\n            self.logger.error(\"\u274c TTS test failed\")\n        \n        return success\n    \n    def shutdown(self):\n        \"\"\"Shutdown all TTS engines.\"\"\"\n        self.logger.info(\"Shutting down TTS module...\")\n        \n        for engine in self.engines.values():\n            engine.shutdown()\n        \n        self.engines.clear()\n        self.current_engine = None\n        self.fallback_engines.clear()\n        \n        self.logger.info(\"TTS module shutdown complete\")"
    },
    "AUTONOMOUS_CONFIG.json": {
      "content": "{\n  \"autonomous_mode\": \"24/7_ACTIVE\",\n  \"brain_coordinator\": \"Amazon Q Developer (YOU)\",\n  \"mission\": \"Complete GEM OS with accessibility-first approach\",\n  \"deadline_days\": 20,\n  \"cycle_interval_seconds\": 1800,\n  \n  \"SACRED_RULES_ENFORCED\": true,\n  \"crash_prevention_active\": true,\n  \"chat_history_protection\": true,\n  \"pycharm_protection\": true,\n  \"gem_daemon_manages_all\": true,\n  \n  \"sacred_rules\": [\n    \"NEVER change file names or create duplicates of existing files\",\n    \"NEVER remove functions/software - Only add improvements\",\n    \"ONLY add improvements - Build upon existing work\", \n    \"ONLY remove code if causing critical errors\",\n    \"ALWAYS analyze partner contributions first - Amazon Q coordinates all\",\n    \"GEM_DAEMON manages ALL background processes - Slack, ngrok, AI team, voice, performance\",\n    \"ALL new integrations MUST be added to gem_daemon.py - NEVER create separate daemons\"\n  ],\n  \n  \"crash_prevention_rules\": [\n    \"Backup chat history before any major operation\",\n    \"Preserve PyCharm state and prevent IDE crashes\", \n    \"Use emergency fallback if system becomes unstable\",\n    \"Monitor memory usage and system health continuously\"\n  ],\n  \n  \"main_objectives\": {\n    \"LISTEN\": \"Perfect speech recognition and audio input\",\n    \"TALK\": \"Natural, accessible text-to-speech output\", \n    \"TAKE_ACTION\": \"Execute commands and control systems\",\n    \"LEARN_MEMORIZE\": \"Adaptive learning and memory systems\"\n  },\n  \n  \"team_hierarchy\": {\n    \"level_1_brain\": {\n      \"amazon_q_brain\": \"Central coordinator and strategic decision maker\"\n    },\n    \"level_2_managers\": {\n      \"gemini_manager\": \"Quality assurance and execution\",\n      \"claude_accessibility\": \"Accessibility specialist and ethics\"\n    },\n    \"level_3_specialists\": {\n      \"github_copilot\": \"Code generation master\",\n      \"tabnine\": \"Intelligence and completion\",\n      \"cursor\": \"AI-first development\",\n      \"codeium\": \"Free AI assistance\",\n      \"continue\": \"Open source AI\",\n      \"ollama\": \"Local AI processing\"\n    },\n    \"level_4_extended\": {\n      \"deepseek\": \"Advanced code generation\",\n      \"codegeex\": \"Multilingual AI\",\n      \"openai_gpt\": \"Advanced reasoning\",\n      \"huggingface\": \"ML models\",\n      \"aws_bedrock\": \"Foundation models\"\n    }\n  },\n  \n  \"continuous_tasks\": [\n    \"Search for issues and improvements\",\n    \"Debug and fix errors immediately\", \n    \"Implement accessibility enhancements\",\n    \"Optimize performance continuously\",\n    \"Add new features for humans\",\n    \"Update documentation and tests\",\n    \"Monitor Slack integration for accessibility requests\"\n  ],\n  \n  \"daemons\": [\n    {\n      \"name\": \"gem_main\",\n      \"command\": \"python3 gem.py\",\n      \"restart_on_failure\": true,\n      \"max_restarts\": 5\n    },\n    {\n      \"name\": \"slack_events\",\n      \"command\": \"/usr/bin/python3 slack_events.py\",\n      \"restart_on_failure\": true,\n      \"max_restarts\": 5\n    }\n  ],\n  \n  \"success_metrics\": {\n    \"LISTEN_working\": false,\n    \"TALK_working\": false,\n    \"TAKE_ACTION_working\": false,\n    \"LEARN_MEMORIZE_working\": false,\n    \"accessibility_score\": 0,\n    \"performance_score\": 0,\n    \"human_satisfaction\": 0\n  }\n}"
    },
    "README.md": {
      "content": "GEM OS is a 100% offline, privacy-first AI voice assistant designed for everyone. It uses local AI (Ollama) and advanced voice processing to provide accessible, intelligent features for health, learning, and productivity, without an internet connection.\n\n\n\n\n\n\n# \ud83d\udc8e GEM OS - Generative Enhanced Microphone\n\n**Assistente de Voz Acess\u00edvel para toda a Humanidade**\n\n![GEM OS Logo](https://img.shields.io/badge/GEM%20OS-v2.0.0-blue?style=for-the-badge&logo=microphone)\n![Python](https://img.shields.io/badge/Python-3.8+-green?style=for-the-badge&logo=python)\n![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)\n![Accessibility](https://img.shields.io/badge/Accessibility-First-purple?style=for-the-badge&logo=accessibility)\n\n## \ud83c\udfaf Mission Statement\n\nCreating an accessible, offline-first AI voice assistant for children, people with disabilities, elderly users, and everyone who needs technology that truly understands and serves humanity.\n\n## \u2728 Key Features\n\n### \ud83d\udd12 **100% Offline & Private**\n- Complete privacy - no data leaves your computer\n- Works without internet connection\n- Local AI processing with Ollama\n\n### \u267f **Accessibility First**\n- Screen reader integration\n- Voice-only operation\n- High contrast mode\n- Magnification tools\n- Keyboard navigation support\n- Multiple language support\n\n### \ud83e\udde0 **Revolutionary AI Intelligence**\n- **Emotion Detection**: Recognizes user emotions and responds empathetically\n- **Memory System**: Remembers conversations and personal preferences\n- **Context Awareness**: Understands conversation context and history\n- **Humanized Responses**: Natural, warm conversations (no more call center feel!)\n- **Real-time Learning**: Continuously improves from interactions\n- **Multi-AI Integration**: Gemini, Claude, Amazon Q working together\n\n### \ud83c\udfa4 **Advanced Voice Processing**\n- **Beautiful Female Voice**: Warm, natural Polly voices (Ruth, Joanna)\n- **Emotion-Aware Speech**: Voice adapts to detected emotions\n- **Multiple STT engines**: Whisper, Vosk, Google with learning\n- **Smart Interruption**: Natural conversation flow handling\n- **Voice Cloning**: Custom voice training capabilities\n- **Multi-language**: Real-time language switching\n\n### \ud83d\udc9a **Health & Wellness**\n- Medication reminders\n- Health metrics tracking\n- Wellness reminders\n- Emergency information\n\n### \ud83d\udcda **Learning & Education**\n- Adaptive learning system\n- Interactive quizzes\n- Progress tracking\n- Personalized lessons\n\n### \ud83d\udccb **Productivity Tools**\n- Task management\n- Smart reminders\n- Note taking\n- Time tracking\n\n## \ud83d\ude80 Quick Start\n\n### 1. Setup\n```bash\n# Clone and setup\ngit clone https://github.com/your-username/gem.git\ncd gem\nchmod +x gem_runner.sh\n\n# Complete system setup\n./gem_runner.sh setup\n```\n\n### 2. Run GEM OS\n```bash\n# Normal operation\n./gem_runner.sh run\n\n# Development mode\n./gem_runner.sh dev\n\n# Voice test\n./gem_runner.sh voice-test\n```\n\n### 3. First Interaction\nSay \"Hey GEM\" or \"Oi GEM\" to activate, then:\n- \"Que horas s\u00e3o?\" - Get current time\n- \"Ajuda\" - See available commands\n- \"Ensinar matem\u00e1tica\" - Start learning\n- \"Criar lembrete\" - Add reminder\n\n## \ud83d\udcc1 Project Structure\n\n```\ngem/\n\u251c\u2500\u2500 \ud83d\ude80 gem_runner.sh          # Enhanced launcher script\n\u251c\u2500\u2500 \ud83d\udccb requirements.txt       # Python dependencies\n\u251c\u2500\u2500 \ud83d\udc8e gem.py                # Main application\n\u251c\u2500\u2500 core/                     # Core system modules\n\u2502   \u251c\u2500\u2500 \ud83c\udfb5 audio_system.py    # Advanced audio management\n\u2502   \u251c\u2500\u2500 \u2699\ufe0f config_manager.py  # Secure, profile-based configuration\n\u2502   \u251c\u2500\u2500 \ud83d\udcbe storage.py         # Database and storage management\n\u2502   \u251c\u2500\u2500 \ud83c\udfa4 stt_module.py      # Speech-to-text engine\n\u2502   \u251c\u2500\u2500 \ud83d\udde3\ufe0f tts_module.py      # Text-to-speech engine\n\u2502   \u251c\u2500\u2500 \ud83e\udd16 llm_handler.py     # AI integration\n\u2502   \u251c\u2500\u2500 \ud83c\udfaf command_executor.py # Command processing\n\u2502   \u2514\u2500\u2500 \ud83d\udcca system_monitor.py # System health monitoring\n\u251c\u2500\u2500 features/                # Feature modules\n\u251c\u2500\u2500 plugins/                 # Extensible plugins (e.g., for new agents)\n\u2502   \u251c\u2500\u2500 \u267f accessibility_tools.py # Accessibility features\n\u2502   \u251c\u2500\u2500 \ud83d\udc9a health_assistant.py   # Health & wellness\n\u2502   \u251c\u2500\u2500 \ud83d\udcda learning_tools.py     # Educational tools\n\u2502   \u2514\u2500\u2500 \ud83d\udccb productivity_tools.py # Productivity features\n\u251c\u2500\u2500 data/                    # Data storage\n\u2502   \u251c\u2500\u2500 models/             # AI models\n\u2502   \u251c\u2500\u2500 database/           # User data\n\u2502   \u251c\u2500\u2500 logs/               # Application logs\n\u2502   \u2514\u2500\u2500 backups/            # Data backups\n\u2514\u2500\u2500 tests/                  # Test suite\n```\n\n## \ud83d\udee0\ufe0f System Requirements\n\n### Minimum Requirements\n- **OS**: Linux, macOS, Windows\n- **Python**: 3.8+\n- **RAM**: 4GB\n- **Storage**: 2GB free space\n- **Audio**: Microphone and speakers\n\n### Recommended\n- **RAM**: 8GB+\n- **CPU**: Multi-core processor\n- **Audio**: Quality microphone for better recognition\n\n## \ud83d\udd27 Configuration\n\nGEM OS uses a profile-based YAML configuration system. On first run, it creates a `default.yaml` file in `~/.gem/config/`.\n\n**\u26a0\ufe0f Important Security Note:** For cloud providers like Gemini or AWS, API keys are loaded from environment variables (e.g., `${GEMINI_API_KEY}`). **Never** hardcode secrets directly into your configuration files.\n\n### Using Google Gemini\n\nTo use Google's Gemini models, we recommend using a `.env` file to manage your API key securely.\n\n1.  **Create a `.env` file**: Copy the `.env.example` file to a new file named `.env`. This file is already in `.gitignore` to keep your secrets safe.\n    ```sh\n    cp .env.example .env\n    ```\n\n2.  **Add your API Key**: Open the new `.env` file and add your key from the Google AI Studio.\n    ```\n    GEMINI_API_KEY=\"YOUR_API_KEY_HERE\"\n    ```\n\n3.  **Update Configuration**: In your `~/.gem/config/default.yaml` file, update the `llm` section to use the `gemini` provider. The application will automatically load the key from your `.env` file.\n    ```yaml\n    llm:\n      provider: \"gemini\" # Switch from \"ollama\" to \"gemini\"\n      model: \"gemini-1.5-flash\" # Or another model like \"gemini-pro\"\n      api_key: \"${GEMINI_API_KEY}\" # Loaded automatically from the environment variable\n    ```\n\n```yaml\n# Example from ~/.gem/config/default.yaml\ngeneral:\n  language: \"pt-BR\"\n  secondary_language: \"en-US\"\n  wake_words: [\"hey gem\", \"oi gem\"]\n  offline_mode: true\n  debug_mode: false\n\naudio:\n  sample_rate: 16000\n  noise_reduction: true\n  auto_gain_control: true\n  \nstt:\n  engine: \"whisper\" # whisper, vosk, google\n  model: \"base\"\n  \ntts:\n  engine: \"pyttsx3\" # pyttsx3, espeak, edge-tts, gtts\n  rate: 120\n  \naccessibility:\n  screen_reader_support: true\n  high_contrast_mode: false\n\nllm:\n  provider: \"ollama\" # ollama, gemini, anthropic, bedrock\n  model: \"phi3:mini\"\n```\n\n## \ud83c\udfae Usage Examples\n\n### Basic Commands\n```\n\"Que horas s\u00e3o?\"              # Get current time\n\"Que dia \u00e9 hoje?\"             # Get current date\n\"Ajuda\"                       # Show available commands\n\"Desligar\"                    # Shutdown system\n```\n\n### Accessibility\n```\n\"Ler tela\"                    # Read screen content\n\"Aumentar texto\"              # Zoom in\n\"Alto contraste\"              # Toggle high contrast\n\"Modo emerg\u00eancia\"             # Emergency accessibility mode\n```\n\n### Health & Wellness\n```\n\"Lembrar medicamento aspirina \u00e0s 8 horas\"\n\"Registrar press\u00e3o 120 por 80\"\n\"Como est\u00e1 minha sa\u00fade?\"\n\"Informa\u00e7\u00f5es de emerg\u00eancia\"\n```\n\n### Learning\n```\n\"Ensinar matem\u00e1tica\"          # Start math lesson\n\"Quiz de portugu\u00eas\"           # Portuguese quiz\n\"Praticar ingl\u00eas\"            # English practice\n\"Meu progresso em ci\u00eancias\"   # Learning progress\n```\n\n### Productivity\n```\n\"Criar tarefa comprar leite\"  # Create task\n\"Listar tarefas\"             # List tasks\n\"Lembrete em 30 minutos\"     # Set reminder\n\"Criar nota reuni\u00e3o\"         # Create note\n```\n\n## \ud83d\udd0c Extensibility\n\n### Adding Custom Commands\n```python\n# In command_executor.py\nself.register_command(\n    patterns=[r\"meu comando (.+)\"],\n    handler=self._handle_my_command,\n    description=\"My custom command\",\n    category=\"custom\"\n)\n```\n\n### Custom TTS Engine\n```python\n# Create new TTS engine\nclass MyTTSEngine(TTSEngine):\n    async def speak(self, text: str) -> bool:\n        # Your implementation\n        pass\n```\n\n## \ud83e\uddea Testing\n\n```bash\n# Run all tests\n./gem_runner.sh test\n\n# Test specific components\npython -m pytest tests/test_audio.py\npython -m pytest tests/test_stt.py\n```\n\n## \ud83d\udd0d Troubleshooting\n\n### Common Issues\n\n**Audio not working:**\n```bash\n# Check audio devices\n./gem_runner.sh audio-test\n\n# Install audio dependencies (Linux)\nsudo apt-get install portaudio19-dev alsa-utils\n```\n\n**STT not recognizing speech:**\n- Check microphone permissions\n- Adjust energy threshold in config\n- Try different STT engine\n\n**TTS not speaking:**\n```bash\n# Test TTS\n./gem_runner.sh voice-test\n\n# Install TTS dependencies\nsudo apt-get install espeak festival\n```\n\n**Ollama connection failed:**\n```bash\n# Install and start Ollama\ncurl -fsSL https://ollama.ai/install.sh | sh\nollama serve\nollama pull phi3:mini\n```\n\n## \ud83e\udd1d Contributing\n\nWe welcome contributions! Please see our contributing guidelines:\n\n1. Fork the repository\n2. Create feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit changes (`git commit -m 'Add amazing feature'`)\n4. Push to branch (`git push origin feature/amazing-feature`)\n5. Open Pull Request\n\n### Development Setup\n```bash\n# Setup development environment\n./gem_runner.sh setup\npython -m pip install -e .\n\n# Run in development mode\n./gem_runner.sh dev --debug\n```\n\n## \ud83d\udcca Performance & Monitoring\n\nGEM OS includes built-in system monitoring:\n\n- **CPU Usage**: Tracks system performance\n- **Memory Usage**: Monitors memory consumption\n- **Audio Quality**: Analyzes audio input/output\n- **Response Times**: Measures system responsiveness\n- **Error Tracking**: Logs and analyzes errors\n\nAccess monitoring data:\n```\n\"Status do sistema\"           # System health\n\"Estat\u00edsticas de uso\"         # Usage statistics\n\"Relat\u00f3rio de performance\"    # Performance report\n```\n\n## \ud83d\udd10 Privacy & Security\n\n- **100% Offline**: No data transmitted to external servers\n- **Local Processing**: All AI processing happens locally\n- **Local Data Storage**: User data is stored locally. (Note: Storage is not yet encrypted by default).\n- **No Telemetry**: No usage data collection\n- **Open Source**: Full transparency in code\n\n## \ud83c\udf0d Internationalization\n\nCurrently supported languages:\n- \ud83c\udde7\ud83c\uddf7 Portuguese (Brazil) - Primary\n- \ud83c\uddfa\ud83c\uddf8 English - Secondary\n- \ud83c\uddea\ud83c\uddf8 Spanish - Planned\n- \ud83c\uddeb\ud83c\uddf7 French - Planned\n\n## \ud83d\udcc8 Roadmap\n\n### Version 2.1 (Next Release)\n- [ ] Mobile app companion\n- [ ] Advanced voice training\n- [ ] Custom wake word creation\n- [ ] Plugin marketplace\n\n### Version 2.2 (Future)\n- [ ] Multi-user support\n- [ ] Advanced health analytics\n- [ ] Smart home integration\n- [ ] Gesture recognition\n\n### Version 3.0 (Long-term)\n- [ ] Emotional intelligence\n- [ ] Advanced learning AI\n- [ ] Predictive assistance\n- [ ] IoT ecosystem integration\n\n## \ud83d\udcc4 License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## \ud83d\ude4f Acknowledgments\n\n- **Ollama Team** - Local AI infrastructure\n- **OpenAI Whisper** - Speech recognition\n- **Accessibility Community** - Guidance and feedback\n- **Open Source Contributors** - Various libraries and tools\n\n## \ud83d\udcde Support\n\n- **Documentation**: [Wiki](wiki-url)\n- **Issues**: [GitHub Issues](issues-url)\n- **Discussions**: [GitHub Discussions](discussions-url)\n- **Email**: support@gem-os.org\n\n## \ud83c\udf1f Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=gem-os/gem&type=Date)](https://star-history.com/#gem-os/gem&Date)\n\n---\n\n**Made with \u2764\ufe0f for accessibility and humanity**\n\n*GEM OS - Where technology serves everyone, everywhere, every time.*\n"
    }
  }
}